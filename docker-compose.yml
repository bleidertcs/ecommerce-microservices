services:
  # Kong API Gateway
  kong:
    image: kong:latest
    container_name: bw-kong
    restart: unless-stopped
    ports:
      - "8000:8000" # HTTP API
      - "8443:8443" # HTTPS API
      - "8001:8001" # Admin API
    environment:
      KONG_DATABASE: "off"
      KONG_DECLARATIVE_CONFIG: /var/lib/kong/kong.yml
      KONG_PROXY_ACCESS_LOG: /dev/stdout
      KONG_ADMIN_ACCESS_LOG: /dev/stdout
      KONG_PROXY_ERROR_LOG: /dev/stderr
      KONG_ADMIN_ERROR_LOG: /dev/stderr
      KONG_ADMIN_LISTEN: 0.0.0.0:8001
      KONG_PROXY_LISTEN: 0.0.0.0:8000
    volumes:
      - ./kong/config.yml:/var/lib/kong/kong.yml:ro
    networks:
      - bw-network
    depends_on:
      - users-service
      - products-service
      - orders-service
    healthcheck:
      test: ["CMD", "kong", "health"]
      interval: 30s
      timeout: 10s
      retries: 3

  # Redis Cache
  redis:
    image: redis:7-alpine
    container_name: bw-redis
    restart: unless-stopped
    ports:
      - "6379:6379"
    command: redis-server --appendonly yes --maxmemory 256mb --maxmemory-policy allkeys-lru
    volumes:
      - redis_data:/data
    networks:
      - bw-network
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 3

  # ========================================
  # SigNoz - All-in-One Observability
  # ========================================

  # ZooKeeper - Required by ClickHouse
  zookeeper:
    image: signoz/zookeeper:3.7.1
    container_name: bw-zookeeper
    restart: unless-stopped
    user: root
    environment:
      - ZOO_SERVER_ID=1
      - ALLOW_ANONYMOUS_LOGIN=yes
      - ZOO_AUTOPURGE_INTERVAL=1
    volumes:
      - zookeeper_data:/bitnami/zookeeper
    networks:
      - bw-network
    healthcheck:
      test:
        - CMD-SHELL
        - curl -s -m 2 http://localhost:8080/commands/ruok | grep error | grep null
      interval: 30s
      timeout: 5s
      retries: 3

  # Init ClickHouse - Download histogram user scripts
  init-clickhouse:
    image: clickhouse/clickhouse-server:25.5.6
    container_name: bw-init-clickhouse
    command:
      - bash
      - -c
      - |
        version="v0.0.1"
        node_os=$$(uname -s | tr '[:upper:]' '[:lower:]')
        node_arch=$$(uname -m | sed s/aarch64/arm64/ | sed s/x86_64/amd64/)
        echo "Fetching histogram-binary for $${node_os}/$${node_arch}"
        cd /tmp
        wget -O histogram-quantile.tar.gz "https://github.com/SigNoz/signoz/releases/download/histogram-quantile%2F$${version}/histogram-quantile_$${node_os}_$${node_arch}.tar.gz"
        tar -xvzf histogram-quantile.tar.gz
        mv histogram-quantile /var/lib/clickhouse/user_scripts/histogramQuantile
    restart: on-failure
    volumes:
      - clickhouse_user_scripts:/var/lib/clickhouse/user_scripts/
    networks:
      - bw-network

  # ClickHouse - Data Storage for Logs, Traces, Metrics
  clickhouse:
    image: clickhouse/clickhouse-server:25.5.6
    container_name: bw-clickhouse
    restart: unless-stopped
    tty: true
    volumes:
      - clickhouse_data:/var/lib/clickhouse/
      - clickhouse_user_scripts:/var/lib/clickhouse/user_scripts/
      - ./monitoring/signoz/clickhouse-config.xml:/etc/clickhouse-server/config.d/logging.xml:ro
      - ./monitoring/signoz/clickhouse-users.xml:/etc/clickhouse-server/users.d/logging.xml:ro
      - ./monitoring/signoz/clickhouse-cluster.xml:/etc/clickhouse-server/config.d/clickhouse-cluster.xml:ro
    environment:
      - CLICKHOUSE_SKIP_USER_SETUP=1
    networks:
      - bw-network
    depends_on:
      init-clickhouse:
        condition: service_completed_successfully
      zookeeper:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "wget", "--spider", "-q", "0.0.0.0:8123/ping"]
      interval: 30s
      timeout: 5s
      retries: 3

  # SigNoz Schema Migrator (sync tables)
  schema-migrator-sync:
    image: signoz/signoz-schema-migrator:v0.129.13
    container_name: bw-schema-migrator-sync
    command:
      - sync
      - --dsn=tcp://clickhouse:9000
      - --up=
    networks:
      - bw-network
    depends_on:
      clickhouse:
        condition: service_healthy
    restart: on-failure

  # SigNoz Schema Migrator (async tables)
  schema-migrator-async:
    image: signoz/signoz-schema-migrator:v0.129.13
    container_name: bw-schema-migrator-async
    command:
      - async
      - --dsn=tcp://clickhouse:9000
      - --up=
    networks:
      - bw-network
    depends_on:
      clickhouse:
        condition: service_healthy
      schema-migrator-sync:
        condition: service_completed_successfully
    restart: on-failure

  # SigNoz Query Service + Frontend (all-in-one)
  signoz:
    image: signoz/signoz:v0.110.1
    container_name: bw-signoz
    restart: unless-stopped
    environment:
      - SIGNOZ_ALERTMANAGER_PROVIDER=signoz
      - SIGNOZ_TELEMETRYSTORE_CLICKHOUSE_DSN=tcp://clickhouse:9000
      - SIGNOZ_SQLSTORE_SQLITE_PATH=/var/lib/signoz/signoz.db
      - STORAGE=clickhouse
      - GODEBUG=netdns=go
      - TELEMETRY_ENABLED=true
      - DEPLOYMENT_TYPE=docker-standalone-amd
    volumes:
      - signoz_data:/var/lib/signoz/
    ports:
      - "8080:8080" # SigNoz UI + API
    networks:
      - bw-network
    depends_on:
      clickhouse:
        condition: service_healthy
      schema-migrator-sync:
        condition: service_completed_successfully
      schema-migrator-async:
        condition: service_completed_successfully
    healthcheck:
      test: ["CMD-SHELL", "bash -c 'true > /dev/tcp/127.0.0.1/8080'"]
      interval: 30s
      timeout: 10s
      retries: 3

  # SigNoz OTel Collector
  signoz-otel-collector:
    image: signoz/signoz-otel-collector:v0.129.13
    container_name: bw-signoz-otel-collector
    restart: unless-stopped
    command:
      - --config=/etc/otel-collector-config.yaml
      - --feature-gates=-pkg.translator.prometheus.NormalizeName
    volumes:
      - ./monitoring/signoz/otel-collector-config.yaml:/etc/otel-collector-config.yaml:ro
    environment:
      - OTEL_RESOURCE_ATTRIBUTES=host.name=bw-signoz-otel-collector,os.type=linux
      - LOW_CARDINAL_EXCEPTION_GROUPING=false
    ports:
      - "4317:4317" # OTLP gRPC
      - "4318:4318" # OTLP HTTP
    networks:
      - bw-network
    depends_on:
      clickhouse:
        condition: service_healthy
      signoz:
        condition: service_started
    healthcheck:
      test: ["CMD-SHELL", "bash -c 'true > /dev/tcp/127.0.0.1/13133'"]
      interval: 30s
      timeout: 5s
      retries: 3

  # Authentik - Identity Provider
  authentik-postgresql:
    image: postgres:15-alpine
    container_name: bw-authentik-db
    restart: unless-stopped
    healthcheck:
      test:
        [
          "CMD-SHELL",
          "pg_isready -d $${AUTHENTIK_POSTGRESQL__NAME} -U $${AUTHENTIK_POSTGRESQL__USER}",
        ]
      start_period: 20s
      interval: 30s
      retries: 5
      timeout: 5s
    networks:
      - bw-network
    volumes:
      - authentik_database:/var/lib/postgresql/data
    environment:
      POSTGRES_PASSWORD: ${AUTHENTIK_POSTGRESQL__PASSWORD:?error}
      POSTGRES_USER: ${AUTHENTIK_POSTGRESQL__USER:?error}
      POSTGRES_DB: ${AUTHENTIK_POSTGRESQL__NAME:?error}

  authentik-redis:
    image: redis:7-alpine
    container_name: bw-authentik-redis
    command: --save 60 1 --loglevel warning
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "redis-cli ping | grep PONG"]
      start_period: 20s
      interval: 30s
      retries: 5
      timeout: 3s
    networks:
      - bw-network

  authentik-server:
    image: ghcr.io/goauthentik/server:2025.12.3
    container_name: bw-authentik-server
    user: root
    restart: unless-stopped
    command: server
    environment:
      AUTHENTIK_REDIS__HOST: authentik-redis
      AUTHENTIK_POSTGRESQL__HOST: authentik-postgresql
      AUTHENTIK_POSTGRESQL__USER: ${AUTHENTIK_POSTGRESQL__USER:?error}
      AUTHENTIK_POSTGRESQL__NAME: ${AUTHENTIK_POSTGRESQL__NAME:?error}
      AUTHENTIK_POSTGRESQL__PASSWORD: ${AUTHENTIK_POSTGRESQL__PASSWORD:?error}
      AUTHENTIK_SECRET_KEY: ${AUTHENTIK_SECRET_KEY:?error}
    volumes:
      - ./authentik/media:/media
      - ./authentik/templates:/templates
    networks:
      - bw-network
    ports:
      - "9000:9000"
      - "9443:9443"
    depends_on:
      authentik-postgresql:
        condition: service_healthy
      authentik-redis:
        condition: service_healthy

  authentik-worker:
    image: ghcr.io/goauthentik/server:2025.12.3
    container_name: bw-authentik-worker
    user: root
    restart: unless-stopped
    command: worker
    environment:
      AUTHENTIK_REDIS__HOST: authentik-redis
      AUTHENTIK_POSTGRESQL__HOST: authentik-postgresql
      AUTHENTIK_POSTGRESQL__USER: ${AUTHENTIK_POSTGRESQL__USER:?error}
      AUTHENTIK_POSTGRESQL__NAME: ${AUTHENTIK_POSTGRESQL__NAME:?error}
      AUTHENTIK_POSTGRESQL__PASSWORD: ${AUTHENTIK_POSTGRESQL__PASSWORD:?error}
      AUTHENTIK_SECRET_KEY: ${AUTHENTIK_SECRET_KEY:?error}
    volumes:
      - ./authentik/media:/media
      - ./authentik/templates:/templates
      - /var/run/docker.sock:/var/run/docker.sock
    networks:
      - bw-network
    depends_on:
      authentik-postgresql:
        condition: service_healthy
      authentik-redis:
        condition: service_healthy

  # RabbitMQ - Message Broker
  rabbitmq:
    image: rabbitmq:3-management-alpine
    container_name: bw-rabbitmq
    restart: unless-stopped
    ports:
      - "5672:5672" # AMQP
      - "15672:15672" # Management UI
    environment:
      RABBITMQ_DEFAULT_USER: guest
      RABBITMQ_DEFAULT_PASS: guest
    volumes:
      - rabbitmq_data:/var/lib/rabbitmq
    networks:
      - bw-network
    healthcheck:
      test: ["CMD", "rabbitmq-diagnostics", "-q", "ping"]
      interval: 10s
      timeout: 5s
      retries: 3

  # NATS - Alternative Message Broker
  nats:
    image: nats:2.10-alpine
    container_name: bw-nats
    command: -m 8222
    restart: unless-stopped
    ports:
      - "4222:4222" # NATS client
      - "8222:8222" # NATS monitoring
    networks:
      - bw-network
    healthcheck:
      test:
        [
          "CMD",
          "wget",
          "--no-verbose",
          "--tries=1",
          "--spider",
          "http://localhost:8222/varz",
        ]
      interval: 10s
      timeout: 5s
      retries: 3

  # Users Service
  users-service:
    build:
      context: ./users
      dockerfile: Dockerfile
    container_name: bw-users-service
    restart: unless-stopped
    ports:
      - "9001:9001" # HTTP API
      - "50051:50051" # gRPC
      - "3001:3001" # TCP Transport
    env_file:
      - ./users/.env
    environment:
      - OTEL_SERVICE_NAME=users-service
      - OTEL_EXPORTER_OTLP_ENDPOINT=172.18.0.15:4317
      - OTEL_EXPORTER_OTLP_PROTOCOL=grpc
      - OTEL_EXPORTER_OTLP_INSECURE=true
      - DATABASE_URL=postgresql://admin:master123@users-db:5432/users?schema=public
      - REDIS_URL=redis://redis:6379
      - NATS_URL=nats://nats:4222
    depends_on:
      users-db:
        condition: service_healthy
    networks:
      - bw-network
    healthcheck:
      test:
        [
          "CMD-SHELL",
          "wget --no-verbose --tries=1 --spider http://localhost:9001/health || exit 1",
        ]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  users-db:
    image: postgres:15-alpine
    container_name: bw-users-db
    restart: unless-stopped
    environment:
      POSTGRES_USER: admin
      POSTGRES_PASSWORD: master123
      POSTGRES_DB: users
    volumes:
      - users_data:/var/lib/postgresql/data
    networks:
      - bw-network
    ports:
      - "15431:5432"
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U admin -d users"]
      interval: 10s
      timeout: 5s
      retries: 5

  # Products Service
  products-service:
    build:
      context: ./products
      dockerfile: Dockerfile
    container_name: bw-products-service
    restart: unless-stopped
    ports:
      - "9002:9002" # HTTP API
      - "50052:50052" # gRPC
      - "3002:3002" # TCP Transport
    env_file:
      - ./products/.env
    environment:
      - OTEL_SERVICE_NAME=products-service
      - OTEL_EXPORTER_OTLP_ENDPOINT=172.18.0.15:4317
      - OTEL_EXPORTER_OTLP_PROTOCOL=grpc
      - OTEL_EXPORTER_OTLP_INSECURE=true
      - DATABASE_URL=postgresql://admin:master123@products-db:5432/products?schema=public
      - REDIS_URL=redis://redis:6379
      - NATS_URL=nats://nats:4222
    depends_on:
      products-db:
        condition: service_healthy
    networks:
      - bw-network
    healthcheck:
      test:
        [
          "CMD-SHELL",
          "wget --no-verbose --tries=1 --spider http://localhost:9002/health || exit 1",
        ]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  products-db:
    image: postgres:15-alpine
    container_name: bw-products-db
    restart: unless-stopped
    environment:
      POSTGRES_USER: admin
      POSTGRES_PASSWORD: master123
      POSTGRES_DB: products
    volumes:
      - products_data:/var/lib/postgresql/data
    networks:
      - bw-network
    ports:
      - "15432:5432"
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U admin -d products"]
      interval: 10s
      timeout: 5s
      retries: 5

  # Orders Service
  orders-service:
    build:
      context: ./orders
      dockerfile: Dockerfile
    container_name: bw-orders-service
    restart: unless-stopped
    ports:
      - "9003:9003" # HTTP API
      - "50053:50053" # gRPC
      - "3003:3003" # TCP Transport
    env_file:
      - ./orders/.env
    environment:
      - OTEL_SERVICE_NAME=orders-service
      - OTEL_EXPORTER_OTLP_ENDPOINT=172.18.0.15:4317
      - OTEL_EXPORTER_OTLP_PROTOCOL=grpc
      - OTEL_EXPORTER_OTLP_INSECURE=true
      - DATABASE_URL=postgresql://admin:master123@orders-db:5432/orders?schema=public
      - REDIS_URL=redis://redis:6379
      - NATS_URL=nats://nats:4222
    depends_on:
      orders-db:
        condition: service_healthy
      rabbitmq:
        condition: service_healthy
    networks:
      - bw-network
    healthcheck:
      test:
        [
          "CMD-SHELL",
          "wget --no-verbose --tries=1 --spider http://localhost:9003/health || exit 1",
        ]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  orders-db:
    image: postgres:15-alpine
    container_name: bw-orders-db
    restart: unless-stopped
    environment:
      POSTGRES_USER: admin
      POSTGRES_PASSWORD: master123
      POSTGRES_DB: orders
    volumes:
      - orders_data:/var/lib/postgresql/data
    networks:
      - bw-network
    ports:
      - "15433:5432"
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U admin -d orders"]
      interval: 10s
      timeout: 5s
      retries: 5

  # Web App (Next.js Frontend)
  web-app:
    build:
      context: ./web-app
      dockerfile: Dockerfile
    container_name: bw-web-app
    restart: unless-stopped
    ports:
      - "3000:3000"
    env_file:
      - ./web-app/.env
    environment:
      - AUTHENTIK_URL=http://authentik-server:9000
      - NEXT_PUBLIC_API_URL=http://kong:8000
    networks:
      - bw-network
    depends_on:
      - kong
      - authentik-server
    healthcheck:
      test:
        [
          "CMD-SHELL",
          'node -e "fetch(''http://localhost:3000'').then(() => process.exit(0)).catch(() => process.exit(1))"',
        ]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

networks:
  bw-network:
    driver: bridge

volumes:
  redis_data:
  clickhouse_data:
  clickhouse_user_scripts:
  signoz_data:
  zookeeper_data:
  rabbitmq_data:
  authentik_database:
  authentik_media:
  users_data:
  products_data:
  orders_data:
